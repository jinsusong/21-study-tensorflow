{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMb5mh/u1yEIiymeo+tJQvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/21-study-tensorflow/blob/main/07%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_O0zwVtPDOy"
      },
      "source": [
        "## 텐서플로2와 머신러닝으로 시작하는 자연어 처리 \n",
        "### 로지스틱 회귀부터 BERT와 GPT2 까지\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVG4MK3S73M"
      },
      "source": [
        "### 텍스트 분류 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvSdv1fPkOZH"
      },
      "source": [
        ": 특정 텍스트를 사람들이 정한 몇 가지 범주 중 어느 범주에 속하는지 분류하는 문제 \n",
        "- 이진 분류 \n",
        "- 다중 범주 분류\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBYajkT1hKf"
      },
      "source": [
        "지도 학습을 통한 텍스트 분류 \n",
        "- 나이브 베이즈 분류 \n",
        "- 서포트 벡터 머신\n",
        "- 신경망\n",
        "- 선형 분류 \n",
        "- 로지스틱 분류\n",
        "- 랜덤 포레스트\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiOgKkby8r0F"
      },
      "source": [
        "비지도 학습을 통한 텍스트 분류 \n",
        "- k-평균 군집화(k-means clustering)\n",
        "- 계측적 군집화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1psZtIq85xY"
      },
      "source": [
        "### 텍스트 유사도 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MaRuXWz9QD-"
      },
      "source": [
        "유사도 측정을 위해 정량화하는 방법\n",
        "- 단순히 같은 단어의 개수를 사용해서 유사도를 판단하는 방법\n",
        "- 형태소로 나누어 형태소를 비교하는 방법\n",
        "- 자소 단위로 나누어 단어를 비교하는 방법 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl79sqhH9lyI"
      },
      "source": [
        "대표적으로 사용되는 4개의 유사도 측정 방법\n",
        "- 자카드 유사도\n",
        "- 유클리디언 유사도\n",
        "- 맨해튼 유사도\n",
        "- 코사인 유사도 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnt3GqyX91zp"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "sent = (\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\",\"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\")\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(sent) # 문장 벡터화 진행\n",
        "\n",
        "idf = tfidf_vectorizer.idf_\n",
        "print(dict(zip(tfidf_vectorizer.get_feature_names(),idf)))\n",
        "# 각 수치에 대한 값 시각화 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG8yJnpZ9k21"
      },
      "source": [
        "자카드 유사도 : 두 문장을 각각 단어의 집합으로 만든 뒤 두 집합을 통해 유사도를 측정하는 방식 중 하나\n",
        "\n",
        " - 유사도를 측정하는 방식은 두 집합의 교집합인 공통된 단어의 개수를 두 집합의 합집합, 즉 전체 단어의 수로 나누면 됨 \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpXMqrw_-1zH"
      },
      "source": [
        "코사인 유사도 : 두 개의 벡터값에서 코사인 각도를 구하는 방법\n",
        "- 단순히 좌표상의 거리를 구하는 다른 유사도 측정 방법에 비해 코사인 유사도는 두 벡터 간의 각도를 구하는 것이라서 방향성의 개념이 더해지기 때문에 일반적으로 성능이 더 좋다 .\n",
        "- 두 문장이 유사하다면 같은 방향으로 가르키고 , 유사하지 않을수록 직교로 표현됨\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuH_BYCi_W62"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueOrjNVr_ghj"
      },
      "source": [
        "유클리디언 유사도 : 가장 기본적인 거리를 측정하는 유사도 공식 \n",
        "- n차원 공간에서 두 점 사이의 거리를 구하는 방식 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmlffhH8_vlV"
      },
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjdn5tfRCpXt"
      },
      "source": [
        "맨해튼 유사도 \n",
        ": 맨새튼 거리를 통해 유사도를 측정하는 방법\n",
        "- 사각형 격자로 이뤄진 지도에서 출발점에서 도착점까지를 가로지르지 않고 갈 수 있는 최단거리를 구하는 공식 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjWu7Ip4DF98"
      },
      "source": [
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "\n",
        "manhattan_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "자연어 생성  : 번역, 챗봇 등의 분야에서 사용중 "
      ],
      "metadata": {
        "id": "RrPwDU2vDQx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 이해하기 "
      ],
      "metadata": {
        "id": "8wLxD8_7EpbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re \n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import utils\n",
        "\n",
        "data_set = tf.keras.utils.get_file(\n",
        "    fname=\"imdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True)\n"
      ],
      "metadata": {
        "id": "OkTNep1ZTDhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"review\"]= []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with open(os.path.join(directory, file_path),\"r\")as file:\n",
        "            data[\"review\"].append(file.read())\n",
        "\n",
        "    return pd.DataFrame.from_dict(data)"
      ],
      "metadata": {
        "id": "UFGqX8xyTbJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data(directory):\n",
        "    pos_df = directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"sentiment\"]=1\n",
        "    neg_df[\"sentiment\"]=0\n",
        "\n",
        "    return pd.concat([pos_df, neg_df])\n",
        "    "
      ],
      "metadata": {
        "id": "VdrsJu7fUA42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = data(os.path.join(os.path.dirname(data_set),\"aclImdb\",\"train\"))\n",
        "test_df = data(os.path.join(os.path.dirname(data_set),\"aclImdb\", \"test\"))"
      ],
      "metadata": {
        "id": "1UMAUKPNUdPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "TcqpHRsYUoe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = list(train_df['review'])\n"
      ],
      "metadata": {
        "id": "1yi6IDdPUtgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열 문장 리스트를 토크나이징 \n",
        "tokenized_reviews = [r.split() for r in reviews]\n",
        "\n",
        "#토크나이징된 리스트에 대한 각 길이를 저장 \n",
        "review_len_by_token = [len(t) for t in tokenized_reviews]\n",
        "\n",
        "#토크나이징된 것을 붙여서 음절의 길이를 저장 \n",
        "review_len_by_eumjeol = [len(s.replace(' ',''))for s in reviews]\n",
        "\n"
      ],
      "metadata": {
        "id": "z4oyg5juU0rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.hist(review_len_by_token, bins=50, alpha=0.5, color='r', label='word')\n",
        "plt.hist(review_len_by_eumjeol, bins=50, alpha=0.5, color='b', label='alphabet')\n",
        "plt.yscale('log',nonposy='clip')\n",
        "plt.title('Review Length Histogram')\n",
        "plt.xlabel('Review Length')\n",
        "plt.ylabel('Number of Reviews')"
      ],
      "metadata": {
        "id": "DnkE-nJLVLFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "print('문장 최대 길이: {}'.format(np.max(review_len_by_token)))\n",
        "print('문장 최소 길이:{}'.format(np.min(review_len_by_token)))\n",
        "print('문장 평균 길이 : {}'.format(np.mean(review_len_by_token)))\n",
        "print('문장 길이 표준편차 : {:.2f}'.format(np.std(review_len_by_token)))\n",
        "print('문장 중간 길이: {}'.format(np.median(review_len_by_token)))\n",
        "#사분위의 대한 경우는 0~100 스케일로 돼 있음 \n",
        "print('제 1사분위 길이 : {} '.format(np.percentile(review_len_by_token,25)))\n",
        "print('제 3사분위 길이 : {} '.format(np.percentile(review_len_by_token,75)))"
      ],
      "metadata": {
        "id": "OvSOFa4AV1d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.boxplot([review_len_by_token],\n",
        "            labels=['token'],\n",
        "            showmeans=True)"
      ],
      "metadata": {
        "id": "SPyus6hkWmpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.boxplot([review_len_by_eumjeol],\n",
        "            labels=['Eumjeol'],\n",
        "            showmeans=True)"
      ],
      "metadata": {
        "id": "JiGF1OcjW34F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "wordcloud= WordCloud(stopwords = STOPWORDS, background_color = 'black', width= 800, height= 600).generate(' '.join(train_df['review']))\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sC2zsXWnXQCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sentiment = train_df['sentiment'].value_counts()\n",
        "fig, axe = plt.subplots(ncols=1)\n",
        "fig.set_size_inches(6,3)\n",
        "sns.countplot(train_df['sentiment'])"
      ],
      "metadata": {
        "id": "4PssJlm2XoXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UjE3BAALX5Ou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}