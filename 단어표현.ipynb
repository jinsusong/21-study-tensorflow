{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOpzo6kpaitgVOiwrBk9bhB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/21-study-tensorflow/blob/main/%EB%8B%A8%EC%96%B4%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_O0zwVtPDOy"
      },
      "source": [
        "# 텐서플로2와 머신러닝으로 시작하는 자연어 처리 \n",
        "## 로지스틱 회귀부터 BERT와 GPT2 까지\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVG4MK3S73M"
      },
      "source": [
        "### 자연어 처리는 크게 어떤 문제를 해결하려고 하느냐에 따라 분류된다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvSdv1fPkOZH"
      },
      "source": [
        "1. 텍스트 분류\n",
        "2. 텍스트 유사도\n",
        "3. 텍스트 생성\n",
        "4. 기계 이해\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBYajkT1hKf"
      },
      "source": [
        "단어 표현 : 자연어를 어떻게 표현할지 정하는 것 \n",
        "\n",
        " - 문제를 해결하기 위한 출발점 \n",
        " - 데이터가 어떤 구조이고, 어떤 특성이 있는지 파악한 후 모델을 만드는 편이 훨씬 좋은 성과를 보여준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGulWh235zJ"
      },
      "source": [
        "단어 표현의 분야 : 텍스트를 자연어 처리를 위한 모델에 적용할 수 있게 언어적인 특성을 반영해서 단어를 수치화하는 방법을 찾는 것 \n",
        " - 단어 임베딩 \n",
        " - 단어 벡터 \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5IbLgnG41W-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWZ2M6MH2vmG"
      },
      "source": [
        "분포 가설 : 비슷한 위치에 나오는 단어는 비슷한 의미를 가진다. \n",
        "\n",
        "- 비슷한 위치에 존재하는 단어는 단어 간의 유사도가 높다고 판단하는 방법\n",
        "- 카운트 기반\n",
        "- 예측 기반 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvLRcxyk5evJ"
      },
      "source": [
        "예측 기반 : 신경망 구조 혹은 어떤한 모델을 사용해 특정 문맥에서 어떤 단어가 나올지를 예측하면서 단어를 벡터로 만드는 방식 \n",
        "- Word2vec\n",
        "- NNLM(Neural Network Language Model)\n",
        "- RNNLM(Recurrent Neural Network Language Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JkgQyOb6jjy"
      },
      "source": [
        "Word2vec은 CBOW 와 SKip - Gram 으로 나뉨 \n",
        "CBOW : 어떤 단어를 문맥 안의 주변 단어를 통해 예측하는 방법 \n",
        "Skip-Gram : 어떤 단어를 가지고 특정 문맥 안의 주변 단어들을 예측 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6i8pA-u607M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}